{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "# Preparing for Data\n",
    "print('==> Preparing data..')\n",
    "\n",
    "# Training Data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "# Testing Data preparation\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        \n",
    "        self.convnet = nn.Sequential(OrderedDict([\n",
    "            ('c1', nn.Conv2d(3, 3, kernel_size=(5, 5))),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('s2', nn.MaxPool2d(kernel_size=(2, 2), stride=2)),\n",
    "            ('c3', nn.Conv2d(3, 16, kernel_size=(5, 5))),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('s4', nn.MaxPool2d(kernel_size=(2, 2), stride=2)),\n",
    "            ('c5', nn.Conv2d(16, 120, kernel_size=(5, 5))),\n",
    "            ('relu5', nn.ReLU())\n",
    "        ]))\n",
    "\n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('f6', nn.Linear(120, 84)),\n",
    "            ('relu6', nn.ReLU()),\n",
    "            ('f7', nn.Linear(84, 10)),\n",
    "            ('sig7', nn.LogSoftmax(dim=-1))\n",
    "        ]))\n",
    "        \n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "\n",
    "    def forward(self, x):\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        \n",
    "        output = self.convnet(x)\n",
    "        output = output.view(x.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "    \n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    count = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        ############################\n",
    "        #### Put your code here ####\n",
    "        ############################\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ###########################\n",
    "        #### End of your codes ####\n",
    "        ###########################\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test( model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.311004\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2.303591\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 2.288186\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 2.217399\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2.166404\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.159452\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 1.991313\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 2.148057\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 1.897762\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 2.004825\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.009946\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 1.857703\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 1.918488\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 1.898615\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 1.850434\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.904829\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 1.857255\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 1.883547\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 1.804602\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 1.745231\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.847703\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 1.812716\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 1.596167\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 1.756468\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 1.814371\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.646180\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 1.752371\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 1.805429\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 1.654823\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 1.653459\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.718191\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 1.765406\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 1.712968\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 1.730559\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 1.591893\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.899566\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 1.690238\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 1.658716\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 1.767702\n",
      "Train Epoch: 1 [31200/50000 (100%)]\tLoss: 1.541881\n",
      "\n",
      "Test set: Average loss: 1.6153, Accuracy: 4028/10000 (40%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.633953\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 1.623463\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 1.710476\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 1.547717\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 1.691930\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.773417\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 1.710324\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 1.691058\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 1.668085\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 1.952150\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.597959\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 1.809399\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 1.558799\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 1.576260\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 1.569643\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.718481\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 1.645447\n",
      "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 1.591136\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 1.652575\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 1.603043\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.441703\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 1.703779\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 1.706661\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 1.660241\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 1.612682\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.699300\n",
      "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 1.534524\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 1.637080\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 1.635453\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 1.471510\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.522827\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 1.553664\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 1.641202\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 1.456607\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 1.504204\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.809919\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 1.599830\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 1.630857\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 1.613429\n",
      "Train Epoch: 2 [31200/50000 (100%)]\tLoss: 1.421451\n",
      "\n",
      "Test set: Average loss: 1.5224, Accuracy: 4481/10000 (45%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.807674\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 1.576382\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 1.583561\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 1.708756\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 1.606816\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.634928\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 1.419482\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 1.769824\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 1.769438\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 1.450582\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.527565\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 1.564934\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 1.332343\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 1.486314\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 1.705081\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.507785\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 1.620758\n",
      "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 1.389364\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 1.540248\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 1.428104\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.647542\n",
      "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 1.656669\n",
      "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 1.623813\n",
      "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 1.587800\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 1.557431\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.468652\n",
      "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 1.596300\n",
      "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 1.559964\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 1.439401\n",
      "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 1.483550\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.485838\n",
      "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 1.495386\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 1.523094\n",
      "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 1.502896\n",
      "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 1.558998\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.621277\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 1.517915\n",
      "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 1.575502\n",
      "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 1.531255\n",
      "Train Epoch: 3 [31200/50000 (100%)]\tLoss: 1.730554\n",
      "\n",
      "Test set: Average loss: 1.4119, Accuracy: 4947/10000 (49%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.625991\n",
      "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 1.446472\n",
      "Train Epoch: 4 [2560/50000 (5%)]\tLoss: 1.447432\n",
      "Train Epoch: 4 [3840/50000 (8%)]\tLoss: 1.536801\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 1.514332\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.689596\n",
      "Train Epoch: 4 [7680/50000 (15%)]\tLoss: 1.513049\n",
      "Train Epoch: 4 [8960/50000 (18%)]\tLoss: 1.538474\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 1.549155\n",
      "Train Epoch: 4 [11520/50000 (23%)]\tLoss: 1.449057\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.626135\n",
      "Train Epoch: 4 [14080/50000 (28%)]\tLoss: 1.677126\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 1.770032\n",
      "Train Epoch: 4 [16640/50000 (33%)]\tLoss: 1.570742\n",
      "Train Epoch: 4 [17920/50000 (36%)]\tLoss: 1.544940\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.506286\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 1.475863\n",
      "Train Epoch: 4 [21760/50000 (43%)]\tLoss: 1.582431\n",
      "Train Epoch: 4 [23040/50000 (46%)]\tLoss: 1.670804\n",
      "Train Epoch: 4 [24320/50000 (49%)]\tLoss: 1.386610\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.440563\n",
      "Train Epoch: 4 [26880/50000 (54%)]\tLoss: 1.496188\n",
      "Train Epoch: 4 [28160/50000 (56%)]\tLoss: 1.431481\n",
      "Train Epoch: 4 [29440/50000 (59%)]\tLoss: 1.730145\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 1.404768\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.365815\n",
      "Train Epoch: 4 [33280/50000 (66%)]\tLoss: 1.685970\n",
      "Train Epoch: 4 [34560/50000 (69%)]\tLoss: 1.430305\n",
      "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 1.466587\n",
      "Train Epoch: 4 [37120/50000 (74%)]\tLoss: 1.509159\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.497012\n",
      "Train Epoch: 4 [39680/50000 (79%)]\tLoss: 1.517587\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 1.463568\n",
      "Train Epoch: 4 [42240/50000 (84%)]\tLoss: 1.393280\n",
      "Train Epoch: 4 [43520/50000 (87%)]\tLoss: 1.667523\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.584877\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 1.425432\n",
      "Train Epoch: 4 [47360/50000 (95%)]\tLoss: 1.551766\n",
      "Train Epoch: 4 [48640/50000 (97%)]\tLoss: 1.522833\n",
      "Train Epoch: 4 [31200/50000 (100%)]\tLoss: 1.413280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4205, Accuracy: 4970/10000 (50%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.459113\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 1.465025\n",
      "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 1.458680\n",
      "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 1.516639\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 1.630658\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.473494\n",
      "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 1.677041\n",
      "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 1.435045\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 1.460568\n",
      "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 1.298710\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.591605\n",
      "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 1.513321\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 1.481442\n",
      "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 1.516635\n",
      "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 1.760884\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.585333\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 1.398991\n",
      "Train Epoch: 5 [21760/50000 (43%)]\tLoss: 1.553396\n",
      "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 1.612370\n",
      "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 1.500973\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.473625\n",
      "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 1.364969\n",
      "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 1.401010\n",
      "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 1.509162\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 1.511621\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.356713\n",
      "Train Epoch: 5 [33280/50000 (66%)]\tLoss: 1.404664\n",
      "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 1.475712\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 1.312312\n",
      "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 1.566425\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.373788\n",
      "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 1.437091\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 1.506014\n",
      "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 1.791101\n",
      "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 1.446068\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.285849\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 1.446840\n",
      "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 1.472386\n",
      "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 1.442510\n",
      "Train Epoch: 5 [31200/50000 (100%)]\tLoss: 1.346812\n",
      "\n",
      "Test set: Average loss: 1.3770, Accuracy: 5092/10000 (51%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.401889\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 1.380576\n",
      "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 1.451193\n",
      "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 1.478733\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 1.391309\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.562783\n",
      "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 1.486792\n",
      "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 1.403366\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 1.527995\n",
      "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 1.515447\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.442533\n",
      "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 1.324227\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 1.483198\n",
      "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 1.575482\n",
      "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 1.541573\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.529724\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 1.397066\n",
      "Train Epoch: 6 [21760/50000 (43%)]\tLoss: 1.441070\n",
      "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 1.575341\n",
      "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 1.442319\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.453169\n",
      "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 1.444065\n",
      "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 1.553313\n",
      "Train Epoch: 6 [29440/50000 (59%)]\tLoss: 1.637281\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 1.578567\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.531720\n",
      "Train Epoch: 6 [33280/50000 (66%)]\tLoss: 1.529599\n",
      "Train Epoch: 6 [34560/50000 (69%)]\tLoss: 1.371794\n",
      "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 1.390059\n",
      "Train Epoch: 6 [37120/50000 (74%)]\tLoss: 1.507685\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.336359\n",
      "Train Epoch: 6 [39680/50000 (79%)]\tLoss: 1.463485\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 1.409902\n",
      "Train Epoch: 6 [42240/50000 (84%)]\tLoss: 1.388293\n",
      "Train Epoch: 6 [43520/50000 (87%)]\tLoss: 1.426027\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.446577\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 1.429812\n",
      "Train Epoch: 6 [47360/50000 (95%)]\tLoss: 1.573097\n",
      "Train Epoch: 6 [48640/50000 (97%)]\tLoss: 1.521400\n",
      "Train Epoch: 6 [31200/50000 (100%)]\tLoss: 1.404047\n",
      "\n",
      "Test set: Average loss: 1.4293, Accuracy: 4996/10000 (50%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.466903\n",
      "Train Epoch: 7 [1280/50000 (3%)]\tLoss: 1.573882\n",
      "Train Epoch: 7 [2560/50000 (5%)]\tLoss: 1.546528\n",
      "Train Epoch: 7 [3840/50000 (8%)]\tLoss: 1.374625\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 1.276201\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.477082\n",
      "Train Epoch: 7 [7680/50000 (15%)]\tLoss: 1.349112\n",
      "Train Epoch: 7 [8960/50000 (18%)]\tLoss: 1.504744\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 1.494011\n",
      "Train Epoch: 7 [11520/50000 (23%)]\tLoss: 1.431689\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.408885\n",
      "Train Epoch: 7 [14080/50000 (28%)]\tLoss: 1.427065\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 1.360227\n",
      "Train Epoch: 7 [16640/50000 (33%)]\tLoss: 1.423330\n",
      "Train Epoch: 7 [17920/50000 (36%)]\tLoss: 1.542122\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.429227\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 1.508948\n",
      "Train Epoch: 7 [21760/50000 (43%)]\tLoss: 1.391122\n",
      "Train Epoch: 7 [23040/50000 (46%)]\tLoss: 1.451613\n",
      "Train Epoch: 7 [24320/50000 (49%)]\tLoss: 1.413720\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.622383\n",
      "Train Epoch: 7 [26880/50000 (54%)]\tLoss: 1.349406\n",
      "Train Epoch: 7 [28160/50000 (56%)]\tLoss: 1.427076\n",
      "Train Epoch: 7 [29440/50000 (59%)]\tLoss: 1.472543\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 1.510937\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.539411\n",
      "Train Epoch: 7 [33280/50000 (66%)]\tLoss: 1.434755\n",
      "Train Epoch: 7 [34560/50000 (69%)]\tLoss: 1.333030\n",
      "Train Epoch: 7 [35840/50000 (72%)]\tLoss: 1.424358\n",
      "Train Epoch: 7 [37120/50000 (74%)]\tLoss: 1.394360\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.417567\n",
      "Train Epoch: 7 [39680/50000 (79%)]\tLoss: 1.314920\n",
      "Train Epoch: 7 [40960/50000 (82%)]\tLoss: 1.319867\n",
      "Train Epoch: 7 [42240/50000 (84%)]\tLoss: 1.705979\n",
      "Train Epoch: 7 [43520/50000 (87%)]\tLoss: 1.469764\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.447324\n",
      "Train Epoch: 7 [46080/50000 (92%)]\tLoss: 1.380667\n",
      "Train Epoch: 7 [47360/50000 (95%)]\tLoss: 1.620778\n",
      "Train Epoch: 7 [48640/50000 (97%)]\tLoss: 1.357219\n",
      "Train Epoch: 7 [31200/50000 (100%)]\tLoss: 1.544868\n",
      "\n",
      "Test set: Average loss: 1.3397, Accuracy: 5289/10000 (53%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.411429\n",
      "Train Epoch: 8 [1280/50000 (3%)]\tLoss: 1.401274\n",
      "Train Epoch: 8 [2560/50000 (5%)]\tLoss: 1.516196\n",
      "Train Epoch: 8 [3840/50000 (8%)]\tLoss: 1.456656\n",
      "Train Epoch: 8 [5120/50000 (10%)]\tLoss: 1.280475\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.380840\n",
      "Train Epoch: 8 [7680/50000 (15%)]\tLoss: 1.214049\n",
      "Train Epoch: 8 [8960/50000 (18%)]\tLoss: 1.368743\n",
      "Train Epoch: 8 [10240/50000 (20%)]\tLoss: 1.386750\n",
      "Train Epoch: 8 [11520/50000 (23%)]\tLoss: 1.507646\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.441270\n",
      "Train Epoch: 8 [14080/50000 (28%)]\tLoss: 1.442564\n",
      "Train Epoch: 8 [15360/50000 (31%)]\tLoss: 1.481022\n",
      "Train Epoch: 8 [16640/50000 (33%)]\tLoss: 1.385727\n",
      "Train Epoch: 8 [17920/50000 (36%)]\tLoss: 1.556626\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.452626\n",
      "Train Epoch: 8 [20480/50000 (41%)]\tLoss: 1.546725\n",
      "Train Epoch: 8 [21760/50000 (43%)]\tLoss: 1.585552\n",
      "Train Epoch: 8 [23040/50000 (46%)]\tLoss: 1.375229\n",
      "Train Epoch: 8 [24320/50000 (49%)]\tLoss: 1.519387\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.518846\n",
      "Train Epoch: 8 [26880/50000 (54%)]\tLoss: 1.365638\n",
      "Train Epoch: 8 [28160/50000 (56%)]\tLoss: 1.532202\n",
      "Train Epoch: 8 [29440/50000 (59%)]\tLoss: 1.622213\n",
      "Train Epoch: 8 [30720/50000 (61%)]\tLoss: 1.313539\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.395891\n",
      "Train Epoch: 8 [33280/50000 (66%)]\tLoss: 1.375270\n",
      "Train Epoch: 8 [34560/50000 (69%)]\tLoss: 1.671916\n",
      "Train Epoch: 8 [35840/50000 (72%)]\tLoss: 1.457395\n",
      "Train Epoch: 8 [37120/50000 (74%)]\tLoss: 1.346623\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.391944\n",
      "Train Epoch: 8 [39680/50000 (79%)]\tLoss: 1.290133\n",
      "Train Epoch: 8 [40960/50000 (82%)]\tLoss: 1.725766\n",
      "Train Epoch: 8 [42240/50000 (84%)]\tLoss: 1.415647\n",
      "Train Epoch: 8 [43520/50000 (87%)]\tLoss: 1.470411\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.458981\n",
      "Train Epoch: 8 [46080/50000 (92%)]\tLoss: 1.332206\n",
      "Train Epoch: 8 [47360/50000 (95%)]\tLoss: 1.462984\n",
      "Train Epoch: 8 [48640/50000 (97%)]\tLoss: 1.340556\n",
      "Train Epoch: 8 [31200/50000 (100%)]\tLoss: 1.516440\n",
      "\n",
      "Test set: Average loss: 1.3665, Accuracy: 5222/10000 (52%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.405492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [1280/50000 (3%)]\tLoss: 1.420969\n",
      "Train Epoch: 9 [2560/50000 (5%)]\tLoss: 1.521347\n",
      "Train Epoch: 9 [3840/50000 (8%)]\tLoss: 1.449654\n",
      "Train Epoch: 9 [5120/50000 (10%)]\tLoss: 1.359341\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 1.448230\n",
      "Train Epoch: 9 [7680/50000 (15%)]\tLoss: 1.407997\n",
      "Train Epoch: 9 [8960/50000 (18%)]\tLoss: 1.411573\n",
      "Train Epoch: 9 [10240/50000 (20%)]\tLoss: 1.450413\n",
      "Train Epoch: 9 [11520/50000 (23%)]\tLoss: 1.372007\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.399669\n",
      "Train Epoch: 9 [14080/50000 (28%)]\tLoss: 1.217958\n",
      "Train Epoch: 9 [15360/50000 (31%)]\tLoss: 1.436423\n",
      "Train Epoch: 9 [16640/50000 (33%)]\tLoss: 1.462525\n",
      "Train Epoch: 9 [17920/50000 (36%)]\tLoss: 1.270680\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.365312\n",
      "Train Epoch: 9 [20480/50000 (41%)]\tLoss: 1.518053\n",
      "Train Epoch: 9 [21760/50000 (43%)]\tLoss: 1.338441\n",
      "Train Epoch: 9 [23040/50000 (46%)]\tLoss: 1.384538\n",
      "Train Epoch: 9 [24320/50000 (49%)]\tLoss: 1.299989\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.638518\n",
      "Train Epoch: 9 [26880/50000 (54%)]\tLoss: 1.404368\n",
      "Train Epoch: 9 [28160/50000 (56%)]\tLoss: 1.488762\n",
      "Train Epoch: 9 [29440/50000 (59%)]\tLoss: 1.614836\n",
      "Train Epoch: 9 [30720/50000 (61%)]\tLoss: 1.496376\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.480250\n",
      "Train Epoch: 9 [33280/50000 (66%)]\tLoss: 1.529385\n",
      "Train Epoch: 9 [34560/50000 (69%)]\tLoss: 1.455047\n",
      "Train Epoch: 9 [35840/50000 (72%)]\tLoss: 1.278839\n",
      "Train Epoch: 9 [37120/50000 (74%)]\tLoss: 1.425755\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.493813\n",
      "Train Epoch: 9 [39680/50000 (79%)]\tLoss: 1.306244\n",
      "Train Epoch: 9 [40960/50000 (82%)]\tLoss: 1.434128\n",
      "Train Epoch: 9 [42240/50000 (84%)]\tLoss: 1.396363\n",
      "Train Epoch: 9 [43520/50000 (87%)]\tLoss: 1.432233\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.408728\n",
      "Train Epoch: 9 [46080/50000 (92%)]\tLoss: 1.566493\n",
      "Train Epoch: 9 [47360/50000 (95%)]\tLoss: 1.341677\n",
      "Train Epoch: 9 [48640/50000 (97%)]\tLoss: 1.517402\n",
      "Train Epoch: 9 [31200/50000 (100%)]\tLoss: 1.402522\n",
      "\n",
      "Test set: Average loss: 1.3464, Accuracy: 5250/10000 (52%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.284439\n",
      "Train Epoch: 10 [1280/50000 (3%)]\tLoss: 1.274844\n",
      "Train Epoch: 10 [2560/50000 (5%)]\tLoss: 1.529795\n",
      "Train Epoch: 10 [3840/50000 (8%)]\tLoss: 1.351899\n",
      "Train Epoch: 10 [5120/50000 (10%)]\tLoss: 1.427070\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 1.583749\n",
      "Train Epoch: 10 [7680/50000 (15%)]\tLoss: 1.526061\n",
      "Train Epoch: 10 [8960/50000 (18%)]\tLoss: 1.623727\n",
      "Train Epoch: 10 [10240/50000 (20%)]\tLoss: 1.404068\n",
      "Train Epoch: 10 [11520/50000 (23%)]\tLoss: 1.578412\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.378270\n",
      "Train Epoch: 10 [14080/50000 (28%)]\tLoss: 1.361322\n",
      "Train Epoch: 10 [15360/50000 (31%)]\tLoss: 1.549472\n",
      "Train Epoch: 10 [16640/50000 (33%)]\tLoss: 1.562987\n",
      "Train Epoch: 10 [17920/50000 (36%)]\tLoss: 1.434582\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.472994\n",
      "Train Epoch: 10 [20480/50000 (41%)]\tLoss: 1.346762\n",
      "Train Epoch: 10 [21760/50000 (43%)]\tLoss: 1.396382\n",
      "Train Epoch: 10 [23040/50000 (46%)]\tLoss: 1.330260\n",
      "Train Epoch: 10 [24320/50000 (49%)]\tLoss: 1.472081\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.525329\n",
      "Train Epoch: 10 [26880/50000 (54%)]\tLoss: 1.363890\n",
      "Train Epoch: 10 [28160/50000 (56%)]\tLoss: 1.412828\n",
      "Train Epoch: 10 [29440/50000 (59%)]\tLoss: 1.590089\n",
      "Train Epoch: 10 [30720/50000 (61%)]\tLoss: 1.375136\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 1.380203\n",
      "Train Epoch: 10 [33280/50000 (66%)]\tLoss: 1.361768\n",
      "Train Epoch: 10 [34560/50000 (69%)]\tLoss: 1.483160\n",
      "Train Epoch: 10 [35840/50000 (72%)]\tLoss: 1.180268\n",
      "Train Epoch: 10 [37120/50000 (74%)]\tLoss: 1.737883\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.451423\n",
      "Train Epoch: 10 [39680/50000 (79%)]\tLoss: 1.574820\n",
      "Train Epoch: 10 [40960/50000 (82%)]\tLoss: 1.469107\n",
      "Train Epoch: 10 [42240/50000 (84%)]\tLoss: 1.553864\n",
      "Train Epoch: 10 [43520/50000 (87%)]\tLoss: 1.400248\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.296642\n",
      "Train Epoch: 10 [46080/50000 (92%)]\tLoss: 1.670241\n",
      "Train Epoch: 10 [47360/50000 (95%)]\tLoss: 1.313813\n",
      "Train Epoch: 10 [48640/50000 (97%)]\tLoss: 1.334873\n",
      "Train Epoch: 10 [31200/50000 (100%)]\tLoss: 1.389529\n",
      "\n",
      "Test set: Average loss: 1.3174, Accuracy: 5401/10000 (54%)\n",
      "\n",
      "Train Epoch: 11 [0/50000 (0%)]\tLoss: 1.301085\n",
      "Train Epoch: 11 [1280/50000 (3%)]\tLoss: 1.405195\n",
      "Train Epoch: 11 [2560/50000 (5%)]\tLoss: 1.309570\n",
      "Train Epoch: 11 [3840/50000 (8%)]\tLoss: 1.456683\n",
      "Train Epoch: 11 [5120/50000 (10%)]\tLoss: 1.493597\n",
      "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 1.427043\n",
      "Train Epoch: 11 [7680/50000 (15%)]\tLoss: 1.454793\n",
      "Train Epoch: 11 [8960/50000 (18%)]\tLoss: 1.384968\n",
      "Train Epoch: 11 [10240/50000 (20%)]\tLoss: 1.321995\n",
      "Train Epoch: 11 [11520/50000 (23%)]\tLoss: 1.263811\n",
      "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 1.370005\n",
      "Train Epoch: 11 [14080/50000 (28%)]\tLoss: 1.421315\n",
      "Train Epoch: 11 [15360/50000 (31%)]\tLoss: 1.451172\n",
      "Train Epoch: 11 [16640/50000 (33%)]\tLoss: 1.473473\n",
      "Train Epoch: 11 [17920/50000 (36%)]\tLoss: 1.318308\n",
      "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 1.569586\n",
      "Train Epoch: 11 [20480/50000 (41%)]\tLoss: 1.503508\n",
      "Train Epoch: 11 [21760/50000 (43%)]\tLoss: 1.414166\n",
      "Train Epoch: 11 [23040/50000 (46%)]\tLoss: 1.387641\n",
      "Train Epoch: 11 [24320/50000 (49%)]\tLoss: 1.420477\n",
      "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 1.429286\n",
      "Train Epoch: 11 [26880/50000 (54%)]\tLoss: 1.565353\n",
      "Train Epoch: 11 [28160/50000 (56%)]\tLoss: 1.469794\n",
      "Train Epoch: 11 [29440/50000 (59%)]\tLoss: 1.363032\n",
      "Train Epoch: 11 [30720/50000 (61%)]\tLoss: 1.328655\n",
      "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 1.466352\n",
      "Train Epoch: 11 [33280/50000 (66%)]\tLoss: 1.487775\n",
      "Train Epoch: 11 [34560/50000 (69%)]\tLoss: 1.536108\n",
      "Train Epoch: 11 [35840/50000 (72%)]\tLoss: 1.265705\n",
      "Train Epoch: 11 [37120/50000 (74%)]\tLoss: 1.597396\n",
      "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 1.380647\n",
      "Train Epoch: 11 [39680/50000 (79%)]\tLoss: 1.461209\n",
      "Train Epoch: 11 [40960/50000 (82%)]\tLoss: 1.460332\n",
      "Train Epoch: 11 [42240/50000 (84%)]\tLoss: 1.407803\n",
      "Train Epoch: 11 [43520/50000 (87%)]\tLoss: 1.524634\n",
      "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 1.286259\n",
      "Train Epoch: 11 [46080/50000 (92%)]\tLoss: 1.299025\n",
      "Train Epoch: 11 [47360/50000 (95%)]\tLoss: 1.544351\n",
      "Train Epoch: 11 [48640/50000 (97%)]\tLoss: 1.468810\n",
      "Train Epoch: 11 [31200/50000 (100%)]\tLoss: 1.529505\n",
      "\n",
      "Test set: Average loss: 1.2930, Accuracy: 5498/10000 (55%)\n",
      "\n",
      "Train Epoch: 12 [0/50000 (0%)]\tLoss: 1.451946\n",
      "Train Epoch: 12 [1280/50000 (3%)]\tLoss: 1.412675\n",
      "Train Epoch: 12 [2560/50000 (5%)]\tLoss: 1.326107\n",
      "Train Epoch: 12 [3840/50000 (8%)]\tLoss: 1.461142\n",
      "Train Epoch: 12 [5120/50000 (10%)]\tLoss: 1.392627\n",
      "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 1.563448\n",
      "Train Epoch: 12 [7680/50000 (15%)]\tLoss: 1.547167\n",
      "Train Epoch: 12 [8960/50000 (18%)]\tLoss: 1.295533\n",
      "Train Epoch: 12 [10240/50000 (20%)]\tLoss: 1.520449\n",
      "Train Epoch: 12 [11520/50000 (23%)]\tLoss: 1.478549\n",
      "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 1.494051\n",
      "Train Epoch: 12 [14080/50000 (28%)]\tLoss: 1.373192\n",
      "Train Epoch: 12 [15360/50000 (31%)]\tLoss: 1.415427\n",
      "Train Epoch: 12 [16640/50000 (33%)]\tLoss: 1.203920\n",
      "Train Epoch: 12 [17920/50000 (36%)]\tLoss: 1.400582\n",
      "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 1.298103\n",
      "Train Epoch: 12 [20480/50000 (41%)]\tLoss: 1.517065\n",
      "Train Epoch: 12 [21760/50000 (43%)]\tLoss: 1.593706\n",
      "Train Epoch: 12 [23040/50000 (46%)]\tLoss: 1.468604\n",
      "Train Epoch: 12 [24320/50000 (49%)]\tLoss: 1.459900\n",
      "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 1.602693\n",
      "Train Epoch: 12 [26880/50000 (54%)]\tLoss: 1.329864\n",
      "Train Epoch: 12 [28160/50000 (56%)]\tLoss: 1.362126\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-a6dda13adc0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Traning and Testing total excution time is: %s seconds '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-a6dda13adc0b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-782407c15b13>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \"\"\"\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    time0 = time.time()\n",
    "    # Training settings\n",
    "    batch_size = 128\n",
    "    epochs = 50\n",
    "    lr = 0.05\n",
    "    no_cuda = True\n",
    "    save_model = False\n",
    "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(100)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    \n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "    model = LeNet().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train( model, device, train_loader, optimizer, epoch)\n",
    "        test( model, device, test_loader)\n",
    "\n",
    "    if (save_model):\n",
    "        torch.save(model.state_dict(),\"cifar_lenet.pt\")\n",
    "    time1 = time.time() \n",
    "    print ('Traning and Testing total excution time is: %s seconds ' % (time1-time0))   \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
