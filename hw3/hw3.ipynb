{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "from urllib import request\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Util functions:\n",
    "def load():\n",
    "    with open(file_name,'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "\n",
    "def softmax_prime(z):\n",
    "    return softmax(z) * (1 - softmax(z))\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "\n",
    "# return 1 or 0\n",
    "def relu_prime(z):\n",
    "    return float(z > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_image shape: (60000, 784)\n",
      "Number of images in training set: 60000\n",
      "Number of images in testing set: 10000\n"
     ]
    }
   ],
   "source": [
    "# # Load the training and testing dataset\n",
    "import tensorflow as tf\n",
    "file_name = 'data/mnist.pkl'\n",
    "\n",
    "training_images, training_labels, testing_images, testing_labels = load()\n",
    "\n",
    "# Normalize the data\n",
    "training_images.astype('float32')\n",
    "testing_images.astype('float32')\n",
    "training_images = training_images/255\n",
    "testing_images = testing_images/255\n",
    "\n",
    "print('training_image shape:', training_images.shape)\n",
    "print('Number of images in training set:', training_images.shape[0])\n",
    "print('Number of images in testing set:', testing_images.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weight\n",
    "weights = [np.random.randn(*w) * 0.1 for w in [(784, 200), (200, 50), (50,10)]]\n",
    "\n",
    "# Initialize epoch, batch_size, learning_rate\n",
    "epoch, batch_size, learning_rate = 10, 20, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward(X, weight):\n",
    "#     a = np.array([X])\n",
    "#     for w in weight:\n",
    "#         np.append(a, relu(a[-1].dot(np.array(w))))\n",
    "#     return a\n",
    "# X = [training_images[0:20]]\n",
    "# print(np.shape(X))\n",
    "\n",
    "# print(forward(X, weights))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"output_layer\", output)\n",
    "\n",
    "\n",
    "# def forward(X, weight):\n",
    "#     first = relu(X.dot(weights[0]))\n",
    "#     second = relu(first.dot(weights[1]))\n",
    "#     output = softmax(second.dot(weights[2]))\n",
    "#     return (first_h ,second_h, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 200)\n",
      "(20, 50)\n",
      "(20, 10)\n",
      "finish\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (20,200) into shape (20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-57f301cc5c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mgrads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-57f301cc5c41>\u001b[0m in \u001b[0;36mgrads\u001b[0;34m(X, Y, weights, bias)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m#     a1_delta = z1_delta.sigmoid_derv(a1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0ma3_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mz2_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma3_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-57f301cc5c41>\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(pred, real)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#     print(real[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#     n_samples = real.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m#     print(\"p-r\", pred, real)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#     return pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (20,200) into shape (20)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "\n",
    "def feed_forward(X, weights, bias):\n",
    "    first = relu((np.dot(X, weights[0])))\n",
    "    print(first.shape)\n",
    "    \n",
    "    second = relu((np.dot(first, weights[1])))\n",
    "    print(second.shape)\n",
    "\n",
    "    output = softmax((np.dot(second, weights[2])))\n",
    "    print(output.shape)\n",
    "    print(\"finish\")\n",
    "    return [first ,second, output]\n",
    "\n",
    "def cross_entropy(pred, real):\n",
    "#     print(real[0])\n",
    "#     n_samples = real.shape[0]\n",
    "    res = pred - real\n",
    "#     print(\"p-r\", pred, real)\n",
    "#     return pred\n",
    "    return res/20\n",
    "\n",
    "\n",
    "def grads(X, Y, weights, bias):\n",
    "    grads = np.empty_like(weights)\n",
    "    a = feed_forward(X, weights, bias)\n",
    "    \n",
    "    \n",
    "    \n",
    "#     Feed forward equations:\n",
    "#     z1 = x.w1+b1\n",
    "#     a1 = relu(z1)\n",
    "\n",
    "#     z2 = a1.w2+b2\n",
    "#     a2 = relu(z2)\n",
    "\n",
    "#     z3 = a2.w3+b3\n",
    "#     a3 = softmax(z3)\n",
    "\n",
    "#     Back propagation equations:\n",
    "\n",
    "#     There is no z3_delta and softmax_derv(a3), as explained before.\n",
    "#     a3_delta = a3-y    \n",
    "\n",
    "#     z2_delta = a3_delta.w3.T\n",
    "#     a2_delta = z2_delta.sigmoid_derv(a2)\n",
    "\n",
    "#     z1_delta = a2_delta.w2.T\n",
    "#     a1_delta = z1_delta.sigmoid_derv(a1)\n",
    "    \n",
    "    a3_delta = cross_entropy(a, Y)\n",
    "    \n",
    "    z2_delta = np.dot(a3_delta, weights[-1].T)\n",
    "    \n",
    "    a2_delta = z2_delta * relu_prime(weights[-2]) # w2\n",
    "    \n",
    "    z1_delta = np.dot(a2_delta, weights[-2].T)\n",
    "    \n",
    "    a1_delta = z1_delta * relu_prime(weights[-3]) # w1\n",
    "    \n",
    "    delta = softmax_prime(np.ones(a[-1].shape))\n",
    "    \n",
    "    \n",
    "    weights[2] -= learning_rate * np.dot(weights[1].T, a3_delta)\n",
    "#     bias[2] -= learning_rate * np.sum(a3_delta, axis=0, keepdims=True)\n",
    "    weights[1] -= learning_rate * np.dot(weights[0].T, a2_delta)\n",
    "#     bias[1] -= learning_rate * np.sum(a2_delta, axis=0)\n",
    "    weights[0] -= learning_rate * np.dot(X, a1_delta)\n",
    "#     bias[0] -= learning_rate * np.sum(a1_delta, axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "# trX, trY, teX, teY = load()\n",
    "\n",
    "training_images, training_labels, testing_images, testing_labels\n",
    "\n",
    "\n",
    "weights = [np.random.randn(*w) * 0.1 for w in [(784, 200), (200,50), (50, 10)]]\n",
    "\n",
    "bias = [np.random.randn(*w) * 0.1 for w in [(20, 200), (20,50), (20, 10)]]\n",
    "\n",
    "num_epochs, batch_size, learn_rate = 10, 20, 0.1\n",
    "\n",
    "\n",
    "def vectorize(Y):\n",
    "    length = len(Y)\n",
    "    arr = np.zeros([20,10])\n",
    "    for i in range(length):\n",
    "        arr[i][Y[i]] = 1\n",
    "    return arr\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for j in range(0, len(training_images), batch_size):\n",
    "        X, Y = training_images[j:j+batch_size], training_labels[j:j+batch_size]\n",
    "        Y = vectorize(Y)\n",
    "        grads(X, Y, weights, bias)\n",
    "        \n",
    "    prediction = np.argmax(feed_forward(testing_images, weights, bias)[-1], axis=1)\n",
    "    \n",
    "    \n",
    "    print(i, np.mean(prediction == np.argmax(testing_labels, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.shape(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(weights[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:01<00:00, 962.03it/s]\n",
      "  3%|▎         | 51/1875 [00:00<00:03, 503.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train accuracy: 0.9207666666666666\n",
      "Val accuracy: 0.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 859.39it/s]\n",
      "  2%|▏         | 42/1875 [00:00<00:04, 414.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train accuracy: 0.9361166666666667\n",
      "Val accuracy: 0.9321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 763.72it/s]\n",
      "  2%|▏         | 36/1875 [00:00<00:05, 351.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Train accuracy: 0.9485166666666667\n",
      "Val accuracy: 0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 782.84it/s]\n",
      "  3%|▎         | 51/1875 [00:00<00:03, 508.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Train accuracy: 0.95125\n",
      "Val accuracy: 0.9457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 657.73it/s]\n",
      "  2%|▏         | 41/1875 [00:00<00:04, 404.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Train accuracy: 0.96205\n",
      "Val accuracy: 0.9513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 800.12it/s]\n",
      "  2%|▏         | 37/1875 [00:00<00:05, 362.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Train accuracy: 0.9606833333333333\n",
      "Val accuracy: 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 696.04it/s]\n",
      "  3%|▎         | 49/1875 [00:00<00:03, 485.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Train accuracy: 0.9647666666666667\n",
      "Val accuracy: 0.9521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 640.71it/s]\n",
      "  3%|▎         | 51/1875 [00:00<00:03, 505.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "Train accuracy: 0.9660833333333333\n",
      "Val accuracy: 0.9508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 694.60it/s]\n",
      "  3%|▎         | 64/1875 [00:00<00:02, 636.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "Train accuracy: 0.9699166666666666\n",
      "Val accuracy: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:02<00:00, 716.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "Train accuracy: 0.9718833333333333\n",
      "Val accuracy: 0.9564\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Here you can initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n",
    "        # A dummy layer does nothing\n",
    "        self.weights = np.zeros(shape=(input.shape[1], 10))\n",
    "        bias = np.zeros(shape=(10,))\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Takes input data of shape [batch, input_units], returns output data [batch, 10]\n",
    "        \"\"\"\n",
    "        output = np.matmul(input, self.weights) + bias\n",
    "        return output\n",
    "\n",
    "class Dense(Layer):\n",
    "    def __init__(self, input_units, output_units, learning_rate=0.15):\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # initialize weights with small random numbers. We use normal initialization\n",
    "        self.weights = np.random.randn(input_units, output_units)*0.1\n",
    "        self.biases = np.zeros(output_units)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        return np.matmul(input, self.weights) + self.biases\n",
    "      \n",
    "    def backward(self,input,grad_output):\n",
    "        # compute d f / d x = d f / d dense * d dense / d x\n",
    "        # where d dense/ d x = weights transposed\n",
    "        grad_input = np.dot(grad_output,np.transpose(self.weights))\n",
    "\n",
    "        # compute gradient w.r.t. weights and biases\n",
    "        grad_weights = np.transpose(np.dot(np.transpose(grad_output),input))\n",
    "        grad_biases = np.sum(grad_output, axis = 0)\n",
    "        \n",
    "        # Here we perform a stochastic gradient descent step. \n",
    "        # Later on, you can try replacing that with something better.\n",
    "        self.weights = self.weights - self.learning_rate * grad_weights\n",
    "        self.biases = self.biases - self.learning_rate * grad_biases\n",
    "        return grad_input\n",
    "\n",
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"Apply elementwise ReLU to [batch, input_units] matrix\"\"\"\n",
    "        return np.maximum(0,input)\n",
    "\n",
    "    def backward(self, input, grad_output):\n",
    "        \"\"\"Compute gradient of loss w.r.t. ReLU input\"\"\"\n",
    "        relu_grad = input > 0\n",
    "        return grad_output*relu_grad \n",
    "\n",
    "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"Compute crossentropy from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
    "    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
    "    \n",
    "    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    return xentropy\n",
    "\n",
    "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"Compute crossentropy gradient from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
    "    ones_for_answers = np.zeros_like(logits)\n",
    "    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
    "    \n",
    "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "    \n",
    "    return (- ones_for_answers + softmax) / logits.shape[0]\n",
    "  \n",
    "# Import Dataset\n",
    "import keras\n",
    "def load_dataset(flatten=False):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # normalize x\n",
    "    X_train = X_train.astype(float) / 255.\n",
    "    X_test = X_test.astype(float) / 255.\n",
    "\n",
    "    if flatten:\n",
    "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
    "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
    "    return X_train, y_train, X_test, y_test\n",
    "  \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "X_train, y_train, X_test, y_test = load_dataset(flatten=True)\n",
    "\n",
    "    \n",
    "network = []\n",
    "network.append(Dense(784,200))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(200,50))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(50,10))\n",
    "\n",
    "def forward(network, X):\n",
    "    \"\"\"\n",
    "    Compute activations of all network layers by applying them sequentially.\n",
    "    Return a list of activations for each layer. \n",
    "    Make sure last activation corresponds to network logits.\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    input = X\n",
    "    for i in range(len(network)):\n",
    "        activations.append(network[i].forward(X))\n",
    "        X = network[i].forward(X)\n",
    "        \n",
    "    assert len(activations) == len(network)\n",
    "    return activations\n",
    "\n",
    "def predict(network,X):\n",
    "    \"\"\"\n",
    "    Compute network predictions.\n",
    "    \"\"\"\n",
    "    logits = forward(network,X)[-1]\n",
    "    return logits.argmax(axis=-1)\n",
    "\n",
    "def train(network,X,y):\n",
    "    \"\"\"\n",
    "    Train your network on a given batch of X and y.\n",
    "    You first need to run forward to get all layer activations.\n",
    "    Then you can run layer.backward going from last to first layer.\n",
    "    After you called backward for all layers, all Dense layers have already made one gradient step.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the layer activations\n",
    "    layer_activations = forward(network,X)\n",
    "    layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]\n",
    "    logits = layer_activations[-1]\n",
    "    \n",
    "    # Compute the loss and the initial gradient\n",
    "    loss = softmax_crossentropy_with_logits(logits,y)\n",
    "    loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
    "    \n",
    "    for i in range(1, len(network)):\n",
    "        loss_grad = network[len(network) - i].backward(layer_activations[len(network) - i - 1], loss_grad)\n",
    "    \n",
    "    return np.mean(loss)\n",
    "  \n",
    "from tqdm import trange\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "        \n",
    "train_log = []\n",
    "val_log = []\n",
    "for epoch in range(10):\n",
    "\n",
    "    for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=32,shuffle=True):\n",
    "        train(network,x_batch,y_batch)\n",
    "    \n",
    "    train_log.append(np.mean(predict(network,X_train)==y_train))\n",
    "    val_log.append(np.mean(predict(network,X_test)==y_test))\n",
    "    \n",
    "#     clear_output()\n",
    "    print(\"Epoch\",epoch)\n",
    "    print(\"Train accuracy:\",train_log[-1])\n",
    "    print(\"Val accuracy:\",val_log[-1])\n",
    "    \n",
    "plt.plot(train_log,label='train accuracy')\n",
    "plt.plot(val_log,label='val accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
